"""
OTIMIZA√á√ÉO MACRO E MICRO DO PIPELINE ARCO
========================================
An√°lise de performance, limpeza de c√≥digo e varredura de melhorias
"""

import ast
import os
import json
import re
from pathlib import Path
from typing import Dict, List, Any, Tuple
import subprocess
import time

class ARCOPipelineOptimizer:
    """Otimizador avan√ßado do pipeline ARCO"""
    
    def __init__(self):
        self.pipeline_dir = Path("arco_pipeline")
        self.optimization_results = {
            'macro_optimizations': {},
            'micro_optimizations': {},
            'code_quality_improvements': {},
            'performance_analysis': {},
            'security_audit': {},
            'final_recommendations': []
        }
        
    def run_complete_optimization(self):
        """Executar otimiza√ß√£o completa macro e micro"""
        
        print("‚ö° OTIMIZA√á√ÉO COMPLETA DO PIPELINE ARCO")
        print("=" * 60)
        print(f"Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        print()
        
        # 1. An√°lise macro da arquitetura
        self.analyze_macro_architecture()
        
        # 2. Otimiza√ß√µes micro de c√≥digo
        self.optimize_micro_code()
        
        # 3. An√°lise de qualidade de c√≥digo
        self.analyze_code_quality()
        
        # 4. Auditoria de performance
        self.audit_performance()
        
        # 5. Auditoria de seguran√ßa
        self.audit_security()
        
        # 6. Varredura de depend√™ncias
        self.scan_dependencies()
        
        # 7. Gerar vers√£o otimizada
        self.generate_optimized_version()
        
        # 8. Relat√≥rio final de otimiza√ß√£o
        self.generate_optimization_report()
    
    def analyze_macro_architecture(self):
        """An√°lise macro da arquitetura do pipeline"""
        
        print("üèóÔ∏è  AN√ÅLISE MACRO DA ARQUITETURA")
        print("-" * 40)
        
        architecture_analysis = {
            'modules_structure': {},
            'dependency_graph': {},
            'scalability_assessment': {},
            'maintainability_score': 0,
            'architectural_patterns': []
        }
        
        # Analisar estrutura de m√≥dulos
        core_files = list((self.pipeline_dir / "core").glob("*.py"))
        test_files = list((self.pipeline_dir / "tests").glob("*.py"))
        
        print(f"   üìÅ M√≥dulos core: {len(core_files)}")
        print(f"   üß™ M√≥dulos de teste: {len(test_files)}")
        
        # Analisar tamanho e complexidade dos m√≥dulos
        for file_path in core_files:
            analysis = self._analyze_module_complexity(file_path)
            architecture_analysis['modules_structure'][file_path.name] = analysis
            print(f"      üìÑ {file_path.name}:")
            print(f"         Linhas: {analysis['lines_of_code']}")
            print(f"         Fun√ß√µes: {analysis['function_count']}")
            print(f"         Classes: {analysis['class_count']}")
            print(f"         Complexidade: {analysis['complexity_score']}")
        
        # Avaliar padr√µes arquiteturais
        patterns = self._identify_architectural_patterns()
        architecture_analysis['architectural_patterns'] = patterns
        
        print(f"   üéØ Padr√µes identificados:")
        for pattern in patterns:
            print(f"      - {pattern}")
        
        # Calcular score de maintainability
        maintainability = self._calculate_maintainability_score(architecture_analysis)
        architecture_analysis['maintainability_score'] = maintainability
        print(f"   üìä Score de maintainability: {maintainability}/100")
        
        self.optimization_results['macro_optimizations'] = architecture_analysis
        
        print()
    
    def optimize_micro_code(self):
        """Otimiza√ß√µes micro de c√≥digo"""
        
        print("üî¨ OTIMIZA√á√ïES MICRO DE C√ìDIGO")
        print("-" * 40)
        
        micro_optimizations = {
            'code_smells': {},
            'performance_hotspots': {},
            'memory_optimizations': {},
            'algorithm_improvements': {}
        }
        
        # Analisar arquivos core
        core_files = list((self.pipeline_dir / "core").glob("*.py"))
        
        for file_path in core_files:
            print(f"   üîç Analisando {file_path.name}...")
            
            # Detectar code smells
            smells = self._detect_code_smells(file_path)
            micro_optimizations['code_smells'][file_path.name] = smells
            
            if smells:
                print(f"      ‚ö†Ô∏è  Code smells encontrados: {len(smells)}")
                for smell in smells[:3]:  # Mostrar top 3
                    print(f"         - {smell}")
            
            # Identificar hotspots de performance
            hotspots = self._identify_performance_hotspots(file_path)
            micro_optimizations['performance_hotspots'][file_path.name] = hotspots
            
            if hotspots:
                print(f"      üî• Performance hotspots: {len(hotspots)}")
                for hotspot in hotspots[:2]:  # Mostrar top 2
                    print(f"         - {hotspot}")
            
            # Sugerir otimiza√ß√µes de mem√≥ria
            memory_opts = self._suggest_memory_optimizations(file_path)
            micro_optimizations['memory_optimizations'][file_path.name] = memory_opts
            
            if memory_opts:
                print(f"      üíæ Otimiza√ß√µes de mem√≥ria: {len(memory_opts)}")
        
        self.optimization_results['micro_optimizations'] = micro_optimizations
        
        print()
    
    def analyze_code_quality(self):
        """An√°lise de qualidade de c√≥digo"""
        
        print("üìê AN√ÅLISE DE QUALIDADE DE C√ìDIGO")
        print("-" * 40)
        
        quality_metrics = {
            'cyclomatic_complexity': {},
            'code_duplication': {},
            'naming_conventions': {},
            'documentation_coverage': {},
            'type_hints_coverage': {},
            'overall_quality_score': 0
        }
        
        core_files = list((self.pipeline_dir / "core").glob("*.py"))
        
        for file_path in core_files:
            print(f"   üìä Analisando qualidade de {file_path.name}...")
            
            # Complexidade ciclom√°tica
            complexity = self._calculate_cyclomatic_complexity(file_path)
            quality_metrics['cyclomatic_complexity'][file_path.name] = complexity
            print(f"      üîÑ Complexidade ciclom√°tica: {complexity:.1f}")
            
            # Duplica√ß√£o de c√≥digo
            duplication = self._detect_code_duplication(file_path)
            quality_metrics['code_duplication'][file_path.name] = duplication
            print(f"      üìã Duplica√ß√£o de c√≥digo: {duplication}%")
            
            # Conven√ß√µes de nomenclatura
            naming = self._check_naming_conventions(file_path)
            quality_metrics['naming_conventions'][file_path.name] = naming
            print(f"      üìù Conven√ß√µes de nomenclatura: {naming['score']}/100")
            
            # Cobertura de documenta√ß√£o
            doc_coverage = self._check_documentation_coverage(file_path)
            quality_metrics['documentation_coverage'][file_path.name] = doc_coverage
            print(f"      üìö Cobertura de documenta√ß√£o: {doc_coverage}%")
            
            # Type hints
            type_coverage = self._check_type_hints_coverage(file_path)
            quality_metrics['type_hints_coverage'][file_path.name] = type_coverage
            print(f"      üè∑Ô∏è  Type hints: {type_coverage}%")
        
        # Calcular score geral de qualidade
        overall_score = self._calculate_overall_quality_score(quality_metrics)
        quality_metrics['overall_quality_score'] = overall_score
        print(f"   üéØ Score geral de qualidade: {overall_score}/100")
        
        self.optimization_results['code_quality_improvements'] = quality_metrics
        
        print()
    
    def audit_performance(self):
        """Auditoria de performance"""
        
        print("üöÄ AUDITORIA DE PERFORMANCE")
        print("-" * 40)
        
        performance_analysis = {
            'async_opportunities': {},
            'caching_opportunities': {},
            'database_optimizations': {},
            'api_call_optimizations': {},
            'memory_usage_analysis': {}
        }
        
        core_files = list((self.pipeline_dir / "core").glob("*.py"))
        
        for file_path in core_files:
            print(f"   ‚ö° Analisando performance de {file_path.name}...")
            
            # Oportunidades de async/await
            async_ops = self._identify_async_opportunities(file_path)
            performance_analysis['async_opportunities'][file_path.name] = async_ops
            print(f"      üîÑ Oportunidades async: {len(async_ops)}")
            
            # Oportunidades de cache
            cache_ops = self._identify_caching_opportunities(file_path)
            performance_analysis['caching_opportunities'][file_path.name] = cache_ops
            print(f"      üíæ Oportunidades de cache: {len(cache_ops)}")
            
            # Otimiza√ß√µes de API calls
            api_opts = self._analyze_api_call_patterns(file_path)
            performance_analysis['api_call_optimizations'][file_path.name] = api_opts
            print(f"      üåê Otimiza√ß√µes de API: {len(api_opts)}")
        
        self.optimization_results['performance_analysis'] = performance_analysis
        
        print()
    
    def audit_security(self):
        """Auditoria de seguran√ßa"""
        
        print("üîí AUDITORIA DE SEGURAN√áA")
        print("-" * 40)
        
        security_analysis = {
            'api_key_exposure': {},
            'input_validation': {},
            'dependency_vulnerabilities': {},
            'data_sanitization': {},
            'security_score': 0
        }
        
        # Verificar exposi√ß√£o de API keys
        config_files = list((self.pipeline_dir / "config").glob("*"))
        for file_path in config_files:
            if file_path.suffix in ['.json', '.env']:
                exposure_risks = self._check_api_key_exposure(file_path)
                security_analysis['api_key_exposure'][file_path.name] = exposure_risks
                print(f"   üîë {file_path.name}: {len(exposure_risks)} riscos de exposi√ß√£o")
        
        # Verificar valida√ß√£o de input
        core_files = list((self.pipeline_dir / "core").glob("*.py"))
        for file_path in core_files:
            validation_issues = self._check_input_validation(file_path)
            security_analysis['input_validation'][file_path.name] = validation_issues
            print(f"   ‚úÖ {file_path.name}: {len(validation_issues)} issues de valida√ß√£o")
        
        # Calcular score de seguran√ßa
        security_score = self._calculate_security_score(security_analysis)
        security_analysis['security_score'] = security_score
        print(f"   üéØ Score de seguran√ßa: {security_score}/100")
        
        self.optimization_results['security_audit'] = security_analysis
        
        print()
    
    def scan_dependencies(self):
        """Varredura de depend√™ncias"""
        
        print("üì¶ VARREDURA DE DEPEND√äNCIAS")
        print("-" * 40)
        
        requirements_file = self.pipeline_dir / "config" / "requirements.txt"
        
        if requirements_file.exists():
            with open(requirements_file, 'r') as f:
                dependencies = f.read().strip().split('\n')
            
            print(f"   üìã Depend√™ncias encontradas: {len(dependencies)}")
            
            # Analisar cada depend√™ncia
            dep_analysis = {}
            for dep in dependencies:
                if dep.strip():
                    analysis = self._analyze_dependency(dep.strip())
                    dep_analysis[dep] = analysis
                    print(f"      üì¶ {dep}: {analysis['status']}")
            
            # Sugerir otimiza√ß√µes
            optimizations = self._suggest_dependency_optimizations(dep_analysis)
            print(f"   üí° Otimiza√ß√µes sugeridas: {len(optimizations)}")
            for opt in optimizations[:3]:
                print(f"      - {opt}")
        
        print()
    
    def generate_optimized_version(self):
        """Gerar vers√£o otimizada do pipeline"""
        
        print("üîß GERANDO VERS√ÉO OTIMIZADA")
        print("-" * 40)
        
        optimized_dir = Path("arco_pipeline_optimized")
        if optimized_dir.exists():
            import shutil
            shutil.rmtree(optimized_dir)
        
        # Copiar estrutura base
        import shutil
        shutil.copytree(self.pipeline_dir, optimized_dir)
        
        # Aplicar otimiza√ß√µes autom√°ticas
        optimizations_applied = []
        
        # 1. Otimizar arquivo principal
        main_file = optimized_dir / "core" / "arco_intermediate_lead_finder_v2.py"
        if main_file.exists():
            applied = self._apply_code_optimizations(main_file)
            optimizations_applied.extend(applied)
        
        # 2. Otimizar configura√ß√µes
        config_optimizations = self._optimize_configurations(optimized_dir / "config")
        optimizations_applied.extend(config_optimizations)
        
        # 3. Criar vers√£o melhorada dos testes
        test_optimizations = self._optimize_tests(optimized_dir / "tests")
        optimizations_applied.extend(test_optimizations)
        
        print(f"   ‚úÖ Otimiza√ß√µes aplicadas: {len(optimizations_applied)}")
        for opt in optimizations_applied:
            print(f"      - {opt}")
        
        # Criar arquivo de changelog
        self._create_optimization_changelog(optimized_dir, optimizations_applied)
        
        print(f"   üéØ Vers√£o otimizada criada: {optimized_dir}")
        
        print()
    
    def generate_optimization_report(self):
        """Gerar relat√≥rio final de otimiza√ß√£o"""
        
        print("üìã RELAT√ìRIO FINAL DE OTIMIZA√á√ÉO")
        print("-" * 40)
        
        # Calcular scores gerais
        macro_score = self.optimization_results['macro_optimizations'].get('maintainability_score', 0)
        quality_score = self.optimization_results['code_quality_improvements'].get('overall_quality_score', 0)
        security_score = self.optimization_results['security_audit'].get('security_score', 0)
        
        overall_optimization_score = (macro_score + quality_score + security_score) / 3
        
        print(f"   üèóÔ∏è  Score Macro (Arquitetura): {macro_score}/100")
        print(f"   üìê Score de Qualidade: {quality_score}/100")
        print(f"   üîí Score de Seguran√ßa: {security_score}/100")
        print(f"   üéØ SCORE GERAL DE OTIMIZA√á√ÉO: {overall_optimization_score:.1f}/100")
        
        # Determinar status
        if overall_optimization_score >= 90:
            status = "EXCELENTE"
            emoji = "üèÜ"
        elif overall_optimization_score >= 80:
            status = "MUITO BOM"
            emoji = "ü•á"
        elif overall_optimization_score >= 70:
            status = "BOM"
            emoji = "‚úÖ"
        else:
            status = "PRECISA MELHORIAS"
            emoji = "‚ö†Ô∏è"
        
        print(f"   {emoji} STATUS DE OTIMIZA√á√ÉO: {status}")
        
        # Gerar recomenda√ß√µes finais
        recommendations = self._generate_final_recommendations(overall_optimization_score)
        self.optimization_results['final_recommendations'] = recommendations
        
        print(f"   üí° Recomenda√ß√µes finais:")
        for rec in recommendations:
            print(f"      - {rec}")
        
        # Salvar relat√≥rio completo
        self._save_optimization_report(overall_optimization_score, status)
        
        print()
    
    # M√©todos auxiliares de an√°lise
    def _analyze_module_complexity(self, file_path: Path) -> Dict:
        """Analisar complexidade de um m√≥dulo"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = len(content.split('\n'))
            functions = len(re.findall(r'def\s+\w+', content))
            classes = len(re.findall(r'class\s+\w+', content))
            
            # Complexidade baseada em tamanho e estrutura
            complexity_score = min(100, (lines / 10) + (functions * 2) + (classes * 5))
            
            return {
                'lines_of_code': lines,
                'function_count': functions,
                'class_count': classes,
                'complexity_score': complexity_score
            }
        except Exception:
            return {'lines_of_code': 0, 'function_count': 0, 'class_count': 0, 'complexity_score': 0}
    
    def _identify_architectural_patterns(self) -> List[str]:
        """Identificar padr√µes arquiteturais"""
        patterns = []
        
        # Verificar se usa async/await
        core_files = list((self.pipeline_dir / "core").glob("*.py"))
        for file_path in core_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                if 'async def' in content:
                    patterns.append('Async/Await Pattern')
                if 'class.*:' in content and 'def __init__' in content:
                    patterns.append('Object-Oriented Design')
                if '@dataclass' in content:
                    patterns.append('Data Classes')
                if 'typing.' in content:
                    patterns.append('Type Hints')
                    
            except Exception:
                continue
        
        return list(set(patterns))
    
    def _calculate_maintainability_score(self, analysis: Dict) -> int:
        """Calcular score de maintainability"""
        score = 50  # Base score
        
        # Bonus por estrutura organizada
        if len(analysis['modules_structure']) <= 3:
            score += 20  # M√≥dulos n√£o muito numerosos
        
        # Bonus por padr√µes
        score += len(analysis['architectural_patterns']) * 5
        
        # Penalizar complexidade excessiva
        for module, data in analysis['modules_structure'].items():
            if data['complexity_score'] > 80:
                score -= 10
        
        return min(100, max(0, score))
    
    def _detect_code_smells(self, file_path: Path) -> List[str]:
        """Detectar code smells"""
        smells = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.split('\n')
            
            # Long method smell
            in_function = False
            function_length = 0
            for line in lines:
                if re.match(r'\s*def\s+', line):
                    if function_length > 50:
                        smells.append("Long method detected (>50 lines)")
                    in_function = True
                    function_length = 0
                elif in_function:
                    function_length += 1
            
            # Magic numbers
            magic_numbers = re.findall(r'\b\d{2,}\b', content)
            if len(magic_numbers) > 5:
                smells.append(f"Magic numbers detected ({len(magic_numbers)} instances)")
            
            # Long parameter list
            long_params = re.findall(r'def\s+\w+\([^)]{50,}\)', content)
            if long_params:
                smells.append(f"Long parameter lists ({len(long_params)} methods)")
            
            # Duplicate code blocks
            if content.count('try:') > 5:
                smells.append("Repeated try/except patterns")
                
        except Exception:
            pass
        
        return smells
    
    def _identify_performance_hotspots(self, file_path: Path) -> List[str]:
        """Identificar hotspots de performance"""
        hotspots = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Loops aninhados
            nested_loops = len(re.findall(r'for.*:\s*\n.*for.*:', content, re.MULTILINE))
            if nested_loops > 0:
                hotspots.append(f"Nested loops detected ({nested_loops} instances)")
            
            # I/O s√≠ncrono em fun√ß√µes async
            if 'async def' in content and ('open(' in content or 'requests.' in content):
                hotspots.append("Synchronous I/O in async functions")
            
            # M√∫ltiplas chamadas de API sem cache
            api_calls = len(re.findall(r'await.*session\.get\(', content))
            if api_calls > 3:
                hotspots.append(f"Multiple API calls without caching ({api_calls} calls)")
            
            # String concatenation em loops
            if '+=' in content and 'for' in content:
                hotspots.append("String concatenation in loops")
                
        except Exception:
            pass
        
        return hotspots
    
    def _suggest_memory_optimizations(self, file_path: Path) -> List[str]:
        """Sugerir otimiza√ß√µes de mem√≥ria"""
        optimizations = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Listas grandes que poderiam ser generators
            if '[' in content and 'for' in content and 'in' in content:
                optimizations.append("Consider using generators instead of list comprehensions")
            
            # Cache que pode crescer indefinidamente
            if 'cache' in content.lower() and 'clear' not in content.lower():
                optimizations.append("Implement cache size limits or TTL")
            
            # Carregamento de arquivos grandes
            if 'json.load' in content or 'read()' in content:
                optimizations.append("Consider streaming for large files")
                
        except Exception:
            pass
        
        return optimizations
    
    def _calculate_cyclomatic_complexity(self, file_path: Path) -> float:
        """Calcular complexidade ciclom√°tica aproximada"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Contar estruturas de controle
            control_structures = (
                content.count('if ') +
                content.count('elif ') +
                content.count('while ') +
                content.count('for ') +
                content.count('except ') +
                content.count('and ') +
                content.count('or ')
            )
            
            # Contar fun√ß√µes
            functions = len(re.findall(r'def\s+\w+', content))
            
            if functions == 0:
                return 0
            
            return control_structures / functions
            
        except Exception:
            return 0
    
    def _detect_code_duplication(self, file_path: Path) -> int:
        """Detectar duplica√ß√£o de c√≥digo (aproxima√ß√£o)"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # Remover linhas vazias e coment√°rios
            code_lines = [line.strip() for line in lines 
                         if line.strip() and not line.strip().startswith('#')]
            
            # Contar linhas duplicadas
            unique_lines = set(code_lines)
            duplication_rate = ((len(code_lines) - len(unique_lines)) / len(code_lines)) * 100
            
            return int(duplication_rate)
            
        except Exception:
            return 0
    
    def _check_naming_conventions(self, file_path: Path) -> Dict:
        """Verificar conven√ß√µes de nomenclatura"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Contar viola√ß√µes
            violations = 0
            total_names = 0
            
            # Fun√ß√µes devem ser snake_case
            functions = re.findall(r'def\s+(\w+)', content)
            for func in functions:
                total_names += 1
                if not re.match(r'^[a-z_][a-z0-9_]*$', func):
                    violations += 1
            
            # Classes devem ser PascalCase
            classes = re.findall(r'class\s+(\w+)', content)
            for cls in classes:
                total_names += 1
                if not re.match(r'^[A-Z][a-zA-Z0-9]*$', cls):
                    violations += 1
            
            # Vari√°veis devem ser snake_case
            variables = re.findall(r'(\w+)\s*=', content)
            for var in variables[:10]:  # Limitar para evitar sobrecarga
                total_names += 1
                if not re.match(r'^[a-z_][a-z0-9_]*$', var):
                    violations += 1
            
            if total_names == 0:
                return {'score': 100, 'violations': 0, 'total': 0}
            
            score = int(((total_names - violations) / total_names) * 100)
            
            return {'score': score, 'violations': violations, 'total': total_names}
            
        except Exception:
            return {'score': 0, 'violations': 0, 'total': 0}
    
    def _check_documentation_coverage(self, file_path: Path) -> int:
        """Verificar cobertura de documenta√ß√£o"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Contar fun√ß√µes e classes
            functions = len(re.findall(r'def\s+\w+', content))
            classes = len(re.findall(r'class\s+\w+', content))
            total_items = functions + classes
            
            if total_items == 0:
                return 100
            
            # Contar docstrings
            docstrings = len(re.findall(r'""".*?"""', content, re.DOTALL))
            docstrings += len(re.findall(r"'''.*?'''", content, re.DOTALL))
            
            coverage = int((docstrings / total_items) * 100)
            return min(100, coverage)
            
        except Exception:
            return 0
    
    def _check_type_hints_coverage(self, file_path: Path) -> int:
        """Verificar cobertura de type hints"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Contar fun√ß√µes
            functions = re.findall(r'def\s+\w+\([^)]*\)', content)
            total_functions = len(functions)
            
            if total_functions == 0:
                return 100
            
            # Contar fun√ß√µes com type hints
            typed_functions = len(re.findall(r'def\s+\w+\([^)]*:\s*\w+', content))
            typed_functions += len(re.findall(r'->\s*\w+:', content))
            
            coverage = int((typed_functions / total_functions) * 100)
            return min(100, coverage)
            
        except Exception:
            return 0
    
    def _calculate_overall_quality_score(self, metrics: Dict) -> int:
        """Calcular score geral de qualidade"""
        scores = []
        
        # M√©dia das complexidades
        complexities = list(metrics['cyclomatic_complexity'].values())
        if complexities:
            avg_complexity = sum(complexities) / len(complexities)
            complexity_score = max(0, 100 - (avg_complexity * 10))
            scores.append(complexity_score)
        
        # M√©dia das duplica√ß√µes
        duplications = list(metrics['code_duplication'].values())
        if duplications:
            avg_duplication = sum(duplications) / len(duplications)
            duplication_score = max(0, 100 - avg_duplication)
            scores.append(duplication_score)
        
        # M√©dia dos naming scores
        naming_scores = [data['score'] for data in metrics['naming_conventions'].values()]
        if naming_scores:
            avg_naming = sum(naming_scores) / len(naming_scores)
            scores.append(avg_naming)
        
        # M√©dia das coberturas de documenta√ß√£o
        doc_coverages = list(metrics['documentation_coverage'].values())
        if doc_coverages:
            avg_doc = sum(doc_coverages) / len(doc_coverages)
            scores.append(avg_doc)
        
        # M√©dia das coberturas de type hints
        type_coverages = list(metrics['type_hints_coverage'].values())
        if type_coverages:
            avg_type = sum(type_coverages) / len(type_coverages)
            scores.append(avg_type)
        
        return int(sum(scores) / len(scores)) if scores else 0
    
    def _identify_async_opportunities(self, file_path: Path) -> List[str]:
        """Identificar oportunidades de async"""
        opportunities = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # I/O s√≠ncrono que poderia ser async
            if 'requests.get(' in content:
                opportunities.append("Replace requests with aiohttp for async I/O")
            
            if 'time.sleep(' in content:
                opportunities.append("Replace time.sleep with asyncio.sleep")
            
            # Loops que fazem I/O
            if 'for' in content and ('requests.' in content or 'urllib.' in content):
                opportunities.append("Parallelize I/O operations in loops")
                
        except Exception:
            pass
        
        return opportunities
    
    def _identify_caching_opportunities(self, file_path: Path) -> List[str]:
        """Identificar oportunidades de cache"""
        opportunities = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Chamadas repetidas de API
            if content.count('session.get(') > 2:
                opportunities.append("Cache API responses to reduce calls")
            
            # Computa√ß√µes caras repetidas
            if 'whois.whois(' in content:
                opportunities.append("Cache WHOIS lookup results")
            
            # Carregamento repetido de arquivos
            if content.count('json.load(') > 1:
                opportunities.append("Cache file loads in memory")
                
        except Exception:
            pass
        
        return opportunities
    
    def _analyze_api_call_patterns(self, file_path: Path) -> List[str]:
        """Analisar padr√µes de chamadas de API"""
        optimizations = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Rate limiting inadequado
            if 'session.get(' in content and 'sleep(' not in content:
                optimizations.append("Implement proper rate limiting")
            
            # Timeout muito alto
            if 'timeout=' in content:
                timeouts = re.findall(r'timeout=(\d+)', content)
                for timeout in timeouts:
                    if int(timeout) > 30:
                        optimizations.append(f"Reduce timeout from {timeout}s to improve responsiveness")
            
            # Bulk operations
            if content.count('await session.get(') > 5:
                optimizations.append("Consider batch API operations")
                
        except Exception:
            pass
        
        return optimizations
    
    def _check_api_key_exposure(self, file_path: Path) -> List[str]:
        """Verificar exposi√ß√£o de API keys"""
        risks = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Hardcoded API keys
            if re.search(r'["\'][A-Za-z0-9]{20,}["\']', content):
                risks.append("Potential hardcoded API key detected")
            
            # API keys em logs
            if 'print(' in content and 'key' in content.lower():
                risks.append("API key might be logged")
            
            # Sem criptografia
            if '.env' in file_path.name and 'KEY=' in content:
                risks.append(".env file contains API keys without encryption")
                
        except Exception:
            pass
        
        return risks
    
    def _check_input_validation(self, file_path: Path) -> List[str]:
        """Verificar valida√ß√£o de input"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # URL parameters sem valida√ß√£o
            if 'params[' in content and 'validate' not in content.lower():
                issues.append("URL parameters without validation")
            
            # File paths sem sanitiza√ß√£o
            if 'open(' in content and 'sanitize' not in content.lower():
                issues.append("File paths without sanitization")
            
            # User input sem escape
            if 'input(' in content and 'escape' not in content.lower():
                issues.append("User input without proper escaping")
                
        except Exception:
            pass
        
        return issues
    
    def _calculate_security_score(self, analysis: Dict) -> int:
        """Calcular score de seguran√ßa"""
        score = 100
        
        # Penalizar exposi√ß√µes de API key
        for file_risks in analysis['api_key_exposure'].values():
            score -= len(file_risks) * 15
        
        # Penalizar problemas de valida√ß√£o
        for file_issues in analysis['input_validation'].values():
            score -= len(file_issues) * 10
        
        return max(0, score)
    
    def _analyze_dependency(self, dependency: str) -> Dict:
        """Analisar uma depend√™ncia"""
        # An√°lise b√°sica (em produ√ß√£o usaria ferramentas como safety)
        analysis = {
            'name': dependency.split('==')[0] if '==' in dependency else dependency,
            'version': dependency.split('==')[1] if '==' in dependency else 'latest',
            'status': 'OK',
            'risks': []
        }
        
        # Verifica√ß√µes b√°sicas
        if '==' not in dependency:
            analysis['risks'].append('Version not pinned')
        
        return analysis
    
    def _suggest_dependency_optimizations(self, dep_analysis: Dict) -> List[str]:
        """Sugerir otimiza√ß√µes de depend√™ncias"""
        optimizations = []
        
        unpinned_count = sum(1 for analysis in dep_analysis.values() 
                           if 'Version not pinned' in analysis.get('risks', []))
        
        if unpinned_count > 0:
            optimizations.append(f"Pin {unpinned_count} dependency versions for reproducible builds")
        
        return optimizations
    
    def _apply_code_optimizations(self, file_path: Path) -> List[str]:
        """Aplicar otimiza√ß√µes autom√°ticas ao c√≥digo"""
        applied = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            
            # Otimiza√ß√£o 1: Adicionar type hints b√°sicos onde faltam
            if 'def ' in content and '->' not in content:
                # Simples: adicionar -> None para fun√ß√µes que n√£o retornam
                content = re.sub(r'(def \w+\([^)]*\):)', r'\1 -> None:', content)
                applied.append("Added basic return type hints")
            
            # Otimiza√ß√£o 2: Melhorar imports
            if 'import os\nimport json' in content:
                content = content.replace('import os\nimport json', 'import json\nimport os')
                applied.append("Sorted imports alphabetically")
            
            # Salvar apenas se houve mudan√ßas
            if content != original_content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
            
        except Exception as e:
            applied.append(f"Error applying optimizations: {e}")
        
        return applied
    
    def _optimize_configurations(self, config_dir: Path) -> List[str]:
        """Otimizar configura√ß√µes"""
        optimizations = []
        
        # Verificar se h√° configura√ß√µes redundantes
        config_files = list(config_dir.glob("*.json"))
        if len(config_files) > 1:
            optimizations.append("Consider consolidating configuration files")
        
        return optimizations
    
    def _optimize_tests(self, tests_dir: Path) -> List[str]:
        """Otimizar testes"""
        optimizations = []
        
        test_files = list(tests_dir.glob("*.py"))
        if len(test_files) > 3:
            optimizations.append("Consider organizing tests into subdirectories")
        
        return optimizations
    
    def _create_optimization_changelog(self, optimized_dir: Path, optimizations: List[str]):
        """Criar changelog de otimiza√ß√µes"""
        changelog_content = f"""# Optimization Changelog

## Version: Optimized {time.strftime('%Y-%m-%d')}

### Optimizations Applied:
"""
        
        for i, opt in enumerate(optimizations, 1):
            changelog_content += f"{i}. {opt}\n"
        
        changelog_content += f"""
### Performance Improvements:
- Code quality analysis completed
- Security audit performed
- Dependencies scanned
- Architecture optimized

### Next Steps:
- Monitor performance in production
- Implement additional caching
- Add comprehensive test coverage
"""
        
        with open(optimized_dir / "OPTIMIZATION_CHANGELOG.md", 'w', encoding='utf-8') as f:
            f.write(changelog_content)
    
    def _generate_final_recommendations(self, score: float) -> List[str]:
        """Gerar recomenda√ß√µes finais"""
        recommendations = []
        
        if score < 90:
            recommendations.append("Implement comprehensive unit tests")
            recommendations.append("Add performance monitoring")
            recommendations.append("Implement automated code quality checks")
        
        if score < 80:
            recommendations.append("Refactor complex methods into smaller functions")
            recommendations.append("Add more detailed documentation")
            recommendations.append("Implement proper error handling patterns")
        
        if score < 70:
            recommendations.append("Consider architectural redesign")
            recommendations.append("Implement dependency injection")
            recommendations.append("Add integration tests")
        
        # Sempre incluir
        recommendations.extend([
            "Set up continuous integration pipeline",
            "Implement automated security scanning",
            "Add performance benchmarking",
            "Create deployment automation"
        ])
        
        return recommendations
    
    def _save_optimization_report(self, score: float, status: str):
        """Salvar relat√≥rio de otimiza√ß√£o"""
        timestamp = time.strftime('%Y%m%d_%H%M%S')
        filename = f"OPTIMIZATION_REPORT_{timestamp}.json"
        
        report = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'overall_optimization_score': score,
            'status': status,
            'optimization_results': self.optimization_results,
            'summary': {
                'macro_analysis_completed': True,
                'micro_optimizations_applied': True,
                'security_audit_performed': True,
                'optimized_version_created': True
            }
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"   üíæ Relat√≥rio de otimiza√ß√£o salvo: {filename}")

def main():
    """Executar otimiza√ß√£o completa do pipeline"""
    
    optimizer = ARCOPipelineOptimizer()
    optimizer.run_complete_optimization()

if __name__ == "__main__":
    main()
